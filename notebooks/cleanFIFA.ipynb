{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "RAW_DATA_DIR = '../data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbcc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifa = pd.read_csv(f'{RAW_DATA_DIR}/fifa_combined.csv', dtype= str)\n",
    "df_fbref = pd.read_csv(f'{RAW_DATA_DIR}/fbref_merged_stats.csv', dtype= str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_early_seasons(df):\n",
    "    seasons_to_remove = ['1415', '1516', '1617']\n",
    "    df_filtered = df[~df['season'].isin(seasons_to_remove)]\n",
    "    return df_filtered\n",
    "df_fifa = remove_early_seasons(df_fifa)\n",
    "df_fifa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues  = df_fifa['league_name'].unique()\n",
    "#leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3256aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only FIFA leagues that correspond to FBref leagues\n",
    "fifa_leagues_to_keep = [\n",
    "    'Premier League',      # ENG-Premier League\n",
    "    'La Liga',             # ESP-La Liga\n",
    "    'Ligue 1',             # FRA-Ligue 1\n",
    "    'Bundesliga',          # GER-Bundesliga\n",
    "    'Serie A',             # ITA-Serie A\n",
    "    'Eredivisie',          # NED-Eredivisie\n",
    "    'Liga Portugal',       # POR-Primeira Liga\n",
    "    'Super Lig',           # TUR-Super Lig\n",
    "    'Major League Soccer', # USA-MLS\n",
    "    'Jupiler Pro League',  # BEL-Jupiler Pro League\n",
    "]\n",
    "\n",
    "df_fifa = df_fifa[df_fifa['league_name'].isin(fifa_leagues_to_keep)]\n",
    "df_fifa = df_fifa.dropna()\n",
    "print(f\"Filtered FIFA to {len(df_fifa)} rows in relevant leagues\")\n",
    "df_fifa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aab694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accents from all name columns, keep capitalization!\n",
    "import unicodedata\n",
    "def normalize_name(name):\n",
    "    nfd = unicodedata.normalize('NFD', name)\n",
    "    without_accents = ''.join(c for c in nfd if unicodedata.category(c) != 'Mn')\n",
    "    return without_accents\n",
    "df_fifa['long_name'] = df_fifa['long_name'].apply(normalize_name)\n",
    "df_fifa['short_name'] = df_fifa['short_name'].apply(normalize_name)\n",
    "df_fbref['player'] = df_fbref['player'].apply(normalize_name)\n",
    "df_fifa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b2082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate FBref stats for players who played at multiple clubs in same season\n",
    "# Sum Playing Time columns (cumulative totals), take first for everything else (rates/averages)\n",
    "\n",
    "# Identify Playing Time columns to sum\n",
    "playing_time_cols = [col for col in df_fbref.columns if col.startswith('Playing Time_')]\n",
    "\n",
    "# Columns to keep from first occurrence\n",
    "first_cols = [col for col in df_fbref.columns if col not in ['player', 'season'] + playing_time_cols]\n",
    "\n",
    "# Group by player+season and aggregate\n",
    "agg_dict = {}\n",
    "for col in playing_time_cols:\n",
    "    agg_dict[col] = 'sum'  # Sum playing time totals\n",
    "for col in first_cols:\n",
    "    agg_dict[col] = 'first'  # Take first (primary club) for rates/averages\n",
    "\n",
    "df_fbref_agg = df_fbref.groupby(['player', 'season'], as_index=False).agg(agg_dict)\n",
    "\n",
    "print(f\"Original FBref rows: {len(df_fbref)}\")\n",
    "print(f\"Aggregated FBref rows: {len(df_fbref_agg)}\")\n",
    "print(f\"Duplicate player+seasons removed: {len(df_fbref) - len(df_fbref_agg)}\")\n",
    "df_fbref_agg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize_name(text):\n",
    "    \"\"\"Remove accents, lowercase, and handle punctuation/hyphens\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove accents\n",
    "    nfd = unicodedata.normalize('NFD', str(text))\n",
    "    text = ''.join(c for c in nfd if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Replace hyphens and dots with spaces so 'Heung-min' becomes 'Heung min'\n",
    "    text = re.sub(r'[-.]', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "def is_latin(text):\n",
    "    \"\"\"Check if text contains primarily Latin characters\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    # Count Latin characters (basic Latin + Latin Extended)\n",
    "    latin_chars = sum(1 for c in text if ord(c) < 0x0400 and c.isalpha())\n",
    "    # If more than half are Latin or it's a short word that's fully Latin, keep it\n",
    "    return latin_chars > 0 and (latin_chars >= len([c for c in text if c.isalpha()]) * 0.5)\n",
    "\n",
    "def normalize_team(team_name):\n",
    "    \"\"\"Normalize team names for matching\"\"\"\n",
    "    if pd.isna(team_name):\n",
    "        return \"\"\n",
    "    team = normalize_name(team_name)\n",
    "    # Remove common words that appear in team names\n",
    "    common_words = ['fc', 'afc', 'cf', 'sc', 'united', 'city', 'real', 'athletic', \n",
    "                    'hotspur', 'wanderers', 'rovers', 'albion', 'town', 'county']\n",
    "    words = team.split()\n",
    "    # Keep main identifying word(s), remove common suffixes\n",
    "    filtered = [w for w in words if w not in common_words]\n",
    "    # If we filtered everything, keep original\n",
    "    if not filtered:\n",
    "        filtered = words\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def names_match(name1, name2):\n",
    "    \"\"\"Check if two name parts match, accounting for nicknames and partial matches\"\"\"\n",
    "    if name1 == name2:\n",
    "        return True\n",
    "    # Check if one is a prefix of the other (e.g., Phil vs Philip)\n",
    "    if name1.startswith(name2) or name2.startswith(name1):\n",
    "        return True\n",
    "    # Check if they share first 3+ characters (for very similar names)\n",
    "    if len(name1) >= 3 and len(name2) >= 3 and name1[:3] == name2[:3]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def teams_match(fifa_team, fbref_team):\n",
    "    \"\"\"Check if two teams match\"\"\"\n",
    "    norm_fifa = normalize_team(fifa_team)\n",
    "    norm_fbref = normalize_team(fbref_team)\n",
    "    \n",
    "    if not norm_fifa or not norm_fbref:\n",
    "        return False\n",
    "    \n",
    "    # Direct match\n",
    "    if norm_fifa == norm_fbref:\n",
    "        return True\n",
    "    \n",
    "    # Check if one contains the other (word-level)\n",
    "    fifa_words = set(norm_fifa.split())\n",
    "    fbref_words = set(norm_fbref.split())\n",
    "    \n",
    "    # If there's any substantial overlap (at least one word in common)\n",
    "    common_words = fifa_words & fbref_words\n",
    "    if common_words:\n",
    "        # Check if the common word is substantial (>3 chars)\n",
    "        if any(len(w) > 3 for w in common_words):\n",
    "            return True\n",
    "    \n",
    "    # Check string containment as fallback\n",
    "    if norm_fifa in norm_fbref or norm_fbref in norm_fifa:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# 1. Normalize and split names (Ensures 'heung-min' -> {'heung', 'min'})\n",
    "# Use df_fbref_agg (aggregated) instead of df_fbref to match what we'll merge with\n",
    "df_fbref_agg['name_parts'] = df_fbref_agg['player'].apply(lambda x: set(normalize_name(x).split()))\n",
    "df_fifa['long_name_lower_parts'] = df_fifa['long_name'].apply(lambda x: set(normalize_name(x).split()))\n",
    "df_fifa['short_name_lower_parts'] = df_fifa['short_name'].apply(lambda x: set(normalize_name(x).split()))\n",
    "\n",
    "# 2. Create a lookup dictionary from FBref using season and born as key\n",
    "fbref_lookup = {}\n",
    "for _, row in df_fbref_agg.iterrows():\n",
    "    key = (row['season'], row['born'])\n",
    "    if key not in fbref_lookup:\n",
    "        fbref_lookup[key] = []\n",
    "    fbref_lookup[key].append((row['player'], row['name_parts'], row['team']))\n",
    "\n",
    "# 3. Optimized matching function\n",
    "def match_name(row):\n",
    "    key = (row['season'], row['born'])\n",
    "    candidates = fbref_lookup.get(key)\n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    fifa_all_parts = row['long_name_lower_parts'] | row['short_name_lower_parts']\n",
    "    # Filter out single-letter parts and non-Latin characters\n",
    "    fifa_all_parts = {p for p in fifa_all_parts if len(p) > 1 and is_latin(p)}\n",
    "    \n",
    "    fifa_team = row.get('club_name', '')\n",
    "    \n",
    "    # Strategy 1: Perfect Intersection with Team Match\n",
    "    # If they share at least 2 words, OR they share the only word they have\n",
    "    for player_name, fb_parts, fbref_team in candidates:\n",
    "        fb_parts_filtered = {p for p in fb_parts if len(p) > 1}\n",
    "        \n",
    "        common = fb_parts_filtered.intersection(fifa_all_parts)\n",
    "        \n",
    "        # Condition: If they share at least 2 words, OR they share the only word they have\n",
    "        if len(common) >= 2 or (len(fb_parts_filtered) == 1 and len(common) == 1):\n",
    "            # Double check with team to be safe\n",
    "            if teams_match(fifa_team, fbref_team):\n",
    "                return player_name\n",
    "    \n",
    "    # Strategy 2: Perfect Intersection without Team Match (fallback)\n",
    "    for player_name, fb_parts, fbref_team in candidates:\n",
    "        fb_parts_filtered = {p for p in fb_parts if len(p) > 1}\n",
    "        \n",
    "        common = fb_parts_filtered.intersection(fifa_all_parts)\n",
    "        \n",
    "        # Require at least 2 substantial matches for safety without team\n",
    "        if len(common) >= 2:\n",
    "            return player_name\n",
    "    \n",
    "    # Strategy 3: Subset Fallback with Team Match (For \"H. Son\" where FIFA might only have {\"son\"})\n",
    "    for player_name, fb_parts, fbref_team in candidates:\n",
    "        fb_parts_filtered = {p for p in fb_parts if len(p) > 1}\n",
    "        \n",
    "        if len(fifa_all_parts) > 0 and fifa_all_parts.issubset(fb_parts_filtered):\n",
    "            if teams_match(fifa_team, fbref_team):\n",
    "                # Require at least one substantial match (>2 chars)\n",
    "                if any(len(p) > 2 for p in fifa_all_parts):\n",
    "                    return player_name\n",
    "    \n",
    "    # Strategy 4: Reverse Subset with Team Match (FBref ⊆ FIFA)\n",
    "    for player_name, fb_parts, fbref_team in candidates:\n",
    "        fb_parts_filtered = {p for p in fb_parts if len(p) > 1}\n",
    "        \n",
    "        if len(fb_parts_filtered) > 0 and fb_parts_filtered.issubset(fifa_all_parts):\n",
    "            if teams_match(fifa_team, fbref_team):\n",
    "                return player_name\n",
    "    \n",
    "    # Strategy 5: Fuzzy name matching with Team Match (for nicknames like Phil/Philip)\n",
    "    for player_name, fb_parts, fbref_team in candidates:\n",
    "        if teams_match(fifa_team, fbref_team):\n",
    "            fb_parts_filtered = {p for p in fb_parts if len(p) > 1}\n",
    "            \n",
    "            # Check if we have fuzzy matches\n",
    "            fuzzy_matches = sum(1 for fp in fb_parts_filtered \n",
    "                              if any(names_match(fp, mp) for mp in fifa_all_parts))\n",
    "            \n",
    "            # If most parts match fuzzily\n",
    "            if fuzzy_matches >= len(fb_parts_filtered) * 0.7 and fuzzy_matches > 0:\n",
    "                return player_name\n",
    "    \n",
    "    # Strategy 6: Last resort - any fuzzy match with team (only if single name)\n",
    "    for player_name, fb_parts, fbref_team in candidates:\n",
    "        if teams_match(fifa_team, fbref_team):\n",
    "            fb_parts_filtered = {p for p in fb_parts if len(p) > 1}\n",
    "            if len(fb_parts_filtered) == 1 and any(names_match(list(fb_parts_filtered)[0], mp) for mp in fifa_all_parts):\n",
    "                return player_name\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 4. Apply matching\n",
    "df_fifa['fuzzy_name'] = df_fifa.apply(match_name, axis=1)\n",
    "\n",
    "# Cleanup temporary columns\n",
    "df_fifa.drop(columns=['long_name_lower_parts', 'short_name_lower_parts'], inplace=True)\n",
    "df_fifa.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_cols = df_fifa.columns.tolist()\n",
    "fbref_calls = df_fbref.columns.tolist()\n",
    "print(\"FIFA columns:\", fifa_cols)\n",
    "print(\"FBref columns:\", fbref_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backfill fuzzy_name: For players with missing fuzzy_name in some seasons,\n",
    "# copy the fuzzy_name from other seasons of the same player (same long_name + born)\n",
    "\n",
    "def backfill_fuzzy_names(df):\n",
    "    \"\"\"\n",
    "    For rows where fuzzy_name is NaN, look for other rows with same long_name and born\n",
    "    that have a fuzzy_name, and copy it.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with fuzzy_name column that may have NaN values\n",
    "    \n",
    "    Returns:\n",
    "        Updated dataframe with backfilled fuzzy_name values\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Find rows with missing fuzzy_name\n",
    "    missing_mask = df['fuzzy_name'].isnull()\n",
    "    print(f\"Rows with missing fuzzy_name: {missing_mask.sum()}\")\n",
    "    \n",
    "    if missing_mask.sum() == 0:\n",
    "        print(\"No missing fuzzy_name values to backfill\")\n",
    "        return df\n",
    "    \n",
    "    # Create lookup: (long_name, born) -> fuzzy_name\n",
    "    # Use the first non-null fuzzy_name for each player\n",
    "    player_fuzzy_map = {}\n",
    "    for _, row in df[df['fuzzy_name'].notnull()].iterrows():\n",
    "        key = (row['long_name'], row['born'])\n",
    "        if key not in player_fuzzy_map:\n",
    "            player_fuzzy_map[key] = row['fuzzy_name']\n",
    "    \n",
    "    # Fill missing fuzzy_name values\n",
    "    filled_count = 0\n",
    "    for idx in df[missing_mask].index:\n",
    "        row = df.loc[idx]\n",
    "        key = (row['long_name'], row['born'])\n",
    "        \n",
    "        if key in player_fuzzy_map:\n",
    "            df.at[idx, 'fuzzy_name'] = player_fuzzy_map[key]\n",
    "            filled_count += 1\n",
    "    \n",
    "    print(f\"Backfilled {filled_count} fuzzy_name values from other seasons\")\n",
    "    print(f\"Remaining missing: {df['fuzzy_name'].isnull().sum()}\")\n",
    "    return df\n",
    "\n",
    "print(\"Backfill function created. Usage:\")\n",
    "print(\"df_fifa = backfill_fuzzy_names(df_fifa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the backfill\n",
    "df_fifa = backfill_fuzzy_names(df_fifa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b581a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove no matches\n",
    "df_fifa = df_fifa[df_fifa['fuzzy_name'].notnull()]\n",
    "print(f\"After removing unmatched, FIFA has {len(df_fifa)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c81413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge FIFA with aggregated FBref stats\n",
    "df_merged = df_fifa.merge(\n",
    "    df_fbref_agg, \n",
    "    left_on=['fuzzy_name', 'season'], \n",
    "    right_on=['player', 'season'], \n",
    "    how='inner',  # Use inner since we removed unmatched\n",
    "    suffixes=('_fifa', '_fbref')\n",
    ")\n",
    "\n",
    "print(f\"FIFA rows: {len(df_fifa)}\")\n",
    "print(f\"Merged rows: {len(df_merged)}\")\n",
    "print(f\"Columns: {len(df_merged.columns)}\")\n",
    "\n",
    "# Verify no missing FBref data\n",
    "missing_fbref = df_merged['player'].isnull().sum()\n",
    "if missing_fbref > 0:\n",
    "    print(f\"⚠️  Warning: {missing_fbref} rows missing FBref data after merge\")\n",
    "else:\n",
    "    print(\"✅ All rows have FBref data\")\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f48c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049da3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate column (fuzzy_name = player after merge)\n",
    "df_merged = df_merged.drop(columns=['fuzzy_name'])\n",
    "\n",
    "#df_merged.to_csv('../data/clean/fifa_fbref_merged.csv', index=False)\n",
    "#print(f\"✅ Saved {len(df_merged)} rows to fifa_fbref_merged.csv\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3909f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show where 'pos' is nan\n",
    "df_null = df_merged[df_merged['pos'].isnull()]\n",
    "df_null.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f757ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
